{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c59aa3a-b72c-4f88-8414-767c8cc8f0a9",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Loading Data"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----+-----+-----+---------+\n|      Date| Open| High|  Low|Close|   Volume|\n+----------+-----+-----+-----+-----+---------+\n|1999-11-01|93.25|94.19|92.12|92.37| 26630600|\n|1999-11-02|92.75| 94.5|91.94|92.56| 23174500|\n|1999-11-03|92.94| 93.5| 91.5| 92.0| 22258500|\n|1999-11-04|92.31|92.75|90.31|91.75| 27119700|\n|1999-11-05|91.81|92.87| 90.5|91.56| 35083700|\n|1999-11-08|84.81|90.75|84.37|89.94|121909600|\n|1999-11-09|89.75|89.87|86.44|88.87| 54884900|\n|1999-11-10|88.12|89.12|86.44|87.12| 34692700|\n|1999-11-11|88.25|90.44|88.25|89.62| 34637300|\n|1999-11-12|89.75| 90.0|87.06|89.19| 24707100|\n|1999-11-15|88.25| 88.5|86.94| 87.0| 23540200|\n|1999-11-16|86.94|87.75|85.87|87.31| 29582600|\n|1999-11-17|86.44|87.06| 85.0| 85.0| 33409500|\n|1999-11-18|84.94|85.81| 84.5|84.94| 32246600|\n|1999-11-19|84.44|86.56|84.37| 86.0| 29113000|\n|1999-11-22|89.62|90.37|88.44|89.81| 45298300|\n|1999-11-23|89.25|91.37|88.37|89.62| 35393700|\n|1999-11-24|89.56|92.25| 89.5|91.69| 26885500|\n|1999-11-26|91.62|93.37| 91.0|91.12| 14257100|\n|1999-11-29|90.12|92.06| 89.5|90.19| 25730100|\n+----------+-----+-----+-----+-----+---------+\nonly showing top 20 rows\n\nroot\n |-- Date: date (nullable = true)\n |-- Open: double (nullable = true)\n |-- High: double (nullable = true)\n |-- Low: double (nullable = true)\n |-- Close: double (nullable = true)\n |-- Volume: integer (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# Path to raw data in ADLS\n",
    "raw_data_path = \"/mnt/financial-data/raw/stock_data.csv\"\n",
    "\n",
    "# Load the CSV file into a Spark DataFrame\n",
    "df = spark.read.csv(raw_data_path, header=True, inferSchema=True)\n",
    "\n",
    "df = df.withColumnRenamed(\"_c0\", \"Date\")\n",
    "# Display the first few rows\n",
    "df.show()\n",
    "\n",
    "# Print the schema of the DataFrame\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3bdf6bd3-e653-440b-a1eb-8355dd225092",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Desc"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+------------------+-------------------+------------------+\n|summary|              Open|              High|               Low|             Close|             Volume|      Daily_Change|\n+-------+------------------+------------------+------------------+------------------+-------------------+------------------+\n|  count|              6305|              6305|              6305|              6305|               6305|              6305|\n|   mean| 95.21055770023762| 96.19492713719255|  94.1983865662172| 95.22719563838204|4.509381306962728E7| 1.996574147501986|\n| stddev|105.86132667247786|106.79821086240484|104.82617888104824|105.86565952789142|2.732674267325438E7|2.4697987251266835|\n|    min|              15.2|             15.62|             14.87|             15.15|            5850800|              0.13|\n|    max|             467.0|            468.35|            464.46|            467.56|          591052200|             24.61|\n+-------+------------------+------------------+------------------+------------------+-------------------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Summary statistics for numerical columns\n",
    "df.describe().show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ff72a9a-f6cd-411a-8c12-50178a0d9175",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Null Values"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n||\n++\n||\n++\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Count nulls in each column\n",
    "df.select([col(c).isNull().alias(c) for c in df.columns]).groupBy().sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3babc2be-ac55-40b6-b9ae-2267953a6271",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Monthly Trends"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------------------+------------+\n|Year|Month|         Avg_Close|Total_Volume|\n+----+-----+------------------+------------+\n|1999|   11| 89.46238095238094|   732628000|\n|1999|   12|106.18954545454545|   630488900|\n|2000|    1|107.11399999999999|   637437600|\n|2000|    2| 99.29799999999997|   667243800|\n|2000|    3| 99.81260869565216|  1014093800|\n|2000|    4| 79.00736842105262|  1129073300|\n|2000|    5| 67.07045454545455|   672215400|\n|2000|    6| 73.04409090909093|   733525100|\n|2000|    7| 75.61800000000001|   617092900|\n|2000|    8| 71.07173913043479|   609699900|\n|2000|    9|            65.509|   712766900|\n|2000|   10|58.603636363636355|  1234707800|\n|2000|   11| 68.21095238095238|   991731300|\n|2000|   12| 51.04249999999999|  1028334100|\n|2001|    1|55.780952380952385|  1002765600|\n|2001|    2| 59.32684210526316|   768447800|\n|2001|    3| 55.70454545454545|   947674900|\n|2001|    4| 62.36749999999999|  1037903500|\n|2001|    5| 69.77272727272728|   888652900|\n|2001|    6| 70.61476190476189|   724588900|\n+----+-----+------------------+------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import month, year, avg, sum\n",
    "\n",
    "# Extract year and month\n",
    "df = df.withColumn(\"Year\", year(col(\"Date\"))).withColumn(\"Month\", month(col(\"Date\")))\n",
    "\n",
    "# Monthly average close price and total volume\n",
    "monthly_trends = df.groupBy(\"Year\", \"Month\").agg(\n",
    "    avg(\"Close\").alias(\"Avg_Close\"),\n",
    "    sum(\"Volume\").alias(\"Total_Volume\")\n",
    ")\n",
    "monthly_trends.orderBy(\"Year\", \"Month\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa028c38-4525-4389-aca3-2a7f65a16d6d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Annual Growth Rate- Calculate annual percentage growth in average closing price"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+------------------+-------------------+\n|Year|         Avg_Close|     Prev_Year_Avg|        Growth_Rate|\n+----+------------------+------------------+-------------------+\n|1999| 98.02046511627907|              NULL|               NULL|\n|2000| 76.21960317460321| 98.02046511627907|-22.241132926490483|\n|2001|62.542459677419366| 76.21960317460321|-17.944390848968812|\n|2002|54.549047619047634|62.542459677419366|-12.780776610961645|\n|2003|29.238214285714268|54.549047619047634| -46.40013792742229|\n|2004| 27.12471825396824|29.238214285714268|-7.2285400575187575|\n|2005|25.871030555555564| 27.12471825396824| -4.621938140239546|\n|2006| 26.29079163346613|25.871030555555564|  1.622513942802438|\n|2007| 30.44587609561754| 26.29079163346613| 15.804333776173968|\n|2008|26.647508300395227| 30.44587609561754|-12.475803893089674|\n|2009|22.976555555555564|26.647508300395227| -13.77596998359962|\n|2010|27.058353174603162|22.976555555555564| 17.765054510360017|\n|2011|26.052156746031752|27.058353174603162| -3.718616658148366|\n|2012| 29.82027439999999|26.052156746031752| 14.463745519043053|\n|2013| 32.49138888888888| 29.82027439999999|  8.957377296598205|\n|2014| 42.45334325396824| 32.49138888888888| 30.660290943998604|\n|2015| 46.71357142857142| 42.45334325396824| 10.035082865246334|\n|2016|55.259305555555585| 46.71357142857142| 18.293900178562108|\n|2017| 71.98402390438248|55.259305555555585| 30.265885864259563|\n|2018|101.03398406374497| 71.98402390438248|  40.35612151656041|\n+----+------------------+------------------+-------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import lag\n",
    "\n",
    "# Calculate yearly average close prices\n",
    "yearly_trends = df.groupBy(\"Year\").agg(avg(\"Close\").alias(\"Avg_Close\"))\n",
    "\n",
    "# Define a window to calculate the lag (previous year's Avg_Close)\n",
    "window_spec = Window.orderBy(\"Year\")\n",
    "\n",
    "# Add a column for the previous year's Avg_Close\n",
    "yearly_trends = yearly_trends.withColumn(\"Prev_Year_Avg\", lag(\"Avg_Close\").over(window_spec))\n",
    "\n",
    "# Calculate Growth Rate\n",
    "yearly_trends = yearly_trends.withColumn(\n",
    "    \"Growth_Rate\",\n",
    "    ((col(\"Avg_Close\") - col(\"Prev_Year_Avg\")) / col(\"Prev_Year_Avg\") * 100)\n",
    ")\n",
    "\n",
    "# Show the results\n",
    "yearly_trends.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c02570b9-7d3d-4909-a605-8cfd581585e4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Volatile Days- Find the days with the highest daily price changes"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+------+------+------+--------+------------+----+-----+\n|      Date|    Open|  High|   Low| Close|  Volume|Daily_Change|Year|Month|\n+----------+--------+------+------+------+--------+------------+----+-----+\n|2023-07-18|  345.83|366.78|342.17|359.49|64872705|       24.61|2023|    7|\n|2022-02-24|  272.51|295.16|271.52|294.59|56989686|       23.64|2022|    2|\n|2020-03-13|   147.5|161.91|140.73|158.83|92727446|       21.18|2020|    3|\n|2022-01-24|   292.2|297.11|276.05|296.37|86035393|       21.06|2022|    1|\n|2024-01-31|  406.96|415.32|397.21|397.58|47871097|       18.11|2024|    1|\n|2022-10-13|  219.85| 236.1|219.13|234.24|42551818|       16.97|2022|   10|\n|2022-01-13|320.4658|320.88| 304.0| 304.8|45365979|       16.88|2022|    1|\n|2022-01-26| 307.985| 308.5|293.03|296.71|90428853|       15.47|2022|    1|\n|2022-11-30|  240.57|255.33|239.86|255.14|47594239|       15.47|2022|   11|\n|2024-08-05|  389.17|401.04|385.58|395.15|40709238|       15.46|2024|    8|\n+----------+--------+------+------+------+--------+------------+----+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# Most volatile days\n",
    "volatile_days = df.orderBy(col(\"Daily_Change\").desc()).limit(10)\n",
    "volatile_days.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d52574fa-f737-4862-b2ec-b95405c33a68",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Time Series Analysis"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n|Month|        Avg_Close|\n+-----+-----------------+\n|    1|91.11360749506906|\n|    2|92.56489416666669|\n|    3|91.20604168190128|\n|    4|93.22244941860464|\n|    5|94.25067627118644|\n|    6|95.10028662900191|\n|    7|99.46647628083488|\n|    8|99.18476276978426|\n|    9|98.07370475247524|\n|   10|98.11604710144925|\n|   11|99.28311878557875|\n|   12|90.62514581749056|\n+-----+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Average closing price by month across all years\n",
    "seasonality = df.groupBy(\"Month\").agg(avg(\"Close\").alias(\"Avg_Close\"))\n",
    "seasonality.orderBy(\"Month\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "169f3065-5c7c-4246-9aa0-5f576677152d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Moving Avg - 7_Day_Avg_Close"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+--------+-------+------+--------+------------+---------------+\n|      Date|   Open|    High|    Low| Close|  Volume|Daily_Change|7_Day_Avg_Close|\n+----------+-------+--------+-------+------+--------+------------+---------------+\n|2024-01-02| 373.86|   375.9|366.771|370.87|25258633|        9.13|         370.87|\n|2024-01-03| 369.01|373.2562| 368.51| 370.6|23083465|        4.75|         370.74|\n|2024-01-04|370.665|   373.1| 367.17|367.94|20901502|        5.93|          369.8|\n|2024-01-05| 368.97|  372.06|  366.5|367.75|20074451|        5.56|         369.29|\n|2024-01-08|  369.3|   375.2| 369.01|374.69|23133967|        6.19|         370.37|\n+----------+-------+--------+-------+------+--------+------------+---------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "# Define the window specification for 7-day moving average\n",
    "window_spec = Window.orderBy(\"Date\").rowsBetween(-6, 0)\n",
    "\n",
    "# Add a 7-Day Moving Average column\n",
    "df_filtered = df_filtered.withColumn(\"7_Day_Avg_Close\", round(avg(col(\"Close\")).over(window_spec), 2))\n",
    "df_filtered.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71dbe1dd-e050-4b23-b01c-ed1129f877a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----+-----+-----+--------+------------+----+-----+\n|      Date| Open| High|  Low|Close|  Volume|Daily_Change|Year|Month|\n+----------+-----+-----+-----+-----+--------+------------+----+-----+\n|1999-11-01|93.25|94.19|92.12|92.37|26630600|        2.07|1999|   11|\n|1999-11-02|92.75| 94.5|91.94|92.56|23174500|        2.56|1999|   11|\n|1999-11-03|92.94| 93.5| 91.5| 92.0|22258500|         2.0|1999|   11|\n|1999-11-04|92.31|92.75|90.31|91.75|27119700|        2.44|1999|   11|\n|1999-11-05|91.81|92.87| 90.5|91.56|35083700|        2.37|1999|   11|\n+----------+-----+-----+-----+-----+--------+------------+----+-----+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, round\n",
    "\n",
    "# Add Daily_Change column (High - Low)\n",
    "df = df.withColumn(\"Daily_Change\", round(col(\"High\") - col(\"Low\"), 2))\n",
    "df.show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b03c588-a9f3-4242-89d7-69196e491e4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data with 'Daily_Change' saved to /mnt/financial-data/processed/stock_data_with_daily_change.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the processed data path\n",
    "processed_data_path = \"/mnt/financial-data/processed/stock_data_with_daily_change.csv\"\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "df.write.mode(\"overwrite\").csv(processed_data_path, header=True)\n",
    "\n",
    "print(f\"Processed data with 'Daily_Change' saved to {processed_data_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Insights from stock data",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
